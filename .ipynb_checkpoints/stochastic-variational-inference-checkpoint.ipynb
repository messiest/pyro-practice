{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Variational Inference (SVI) in `pyro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from tqdm import tnrange  # to track progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and guide functions must already be defined.\n",
    "These are taken from part 1 of the tutorial, here: http://pyro.ai/examples/intro_part_ii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyro` has a built in wrapper for PyTorch's optimization library, which allows you to customize the optimization of the model and guide functions independently ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_params = {'lr': 0.005, 'betas':(0.95, 0.999)}\n",
    "adam = optim.Adam(adam_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # parameters of the beta distribution (used as the prior)\n",
    "    alpha0 = torch.tensor(10.)\n",
    "    beta0 = torch.tensor(10.)\n",
    "    \n",
    "    # sample from the beta distribution\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "    # loop over the observed data\n",
    "#     for i in range(len(data)):\n",
    "#         pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "    # conditionally independent implementation\n",
    "#     for i in pyro.irange(\"data_loop\", len(data)):\n",
    "#         pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "    # vectorized conditionally independent implementation with iarange\n",
    "    with pyro.iarange('data_loop', size=100, subsample_size=50) as ind:\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(f), obs=data.index_select(0, ind))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    # register the two variational (learned) parameters\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0), constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0), constraint=constraints.positive)\n",
    "    \n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))  # match the name with the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Toy Data\n",
    "\n",
    "6 heads and 4 tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [torch.tensor(1.) for _ in range(600)] + [torch.tensor(0.) for _ in range(400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(1000)\n",
    "data[:600] = torch.ones(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(\n",
    "    model,\n",
    "    guide,\n",
    "    optim=adam,\n",
    "    loss=Trace_ELBO(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18499588d5d4c15a297f8381f77aabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='SVI Example', max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "\n",
    "n_steps = 5000\n",
    "\n",
    "\n",
    "for step in tnrange(n_steps, desc=\"SVI Example\"):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the learned variational parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the some facts about the beta distribution, we calculate the parameters of distribution, $\\alpha$ and $\\beta$.\n",
    "The pdf of the Beta distribution is \n",
    "\n",
    "$$\n",
    "f(x) = \\frac{x^{\\alpha -1}(1-x)^{\\beta - 1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\n",
    "$$\n",
    "\n",
    "remembering that the _Gamma Function_ is:\n",
    "\n",
    "$$\n",
    "\\Gamma(n) = (n-1)!\n",
    "$$\n",
    "\n",
    "First we compute the inferred mean of the coin's fairness, where\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_mean = alpha_q / (alpha_q + beta_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the data and our prior belief, the fairness of the coin is 0.674 +- 0.084\n"
     ]
    }
   ],
   "source": [
    "inference_str = \"Based on the data and our prior belief, the fairness of the coin is %.3f +- %.3f\"\n",
    "print(inference_str % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimate is to be compared to the exact posterior mean, which in this case is given by $16/30=0.542$. Note that the final estimate of the fairness of the coin is in between the the fairness preferred by the prior ($0.50$) and the fairness suggested by the raw empirical frequencies ($6/10=0.60$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "\n",
    "\n",
    "def gamma(x):\n",
    "    return factorial(x - 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
